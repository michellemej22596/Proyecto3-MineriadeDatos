{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d2067b8",
   "metadata": {},
   "source": [
    "# Selección de Algoritmos y Modelación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800f77d5",
   "metadata": {},
   "source": [
    "1. Especifique su variable respuesta y detalle el tipo de problema que quiere resolver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd63238",
   "metadata": {},
   "source": [
    "El objetivo es construir un modelo que permita predecir la causa probable de muerte de una persona, en función de sus características demográficas. Para ello, se definió como variable respuesta la columna causa, la cual indica el código ICD-10 correspondiente al motivo de defunción registrado oficialmente.\n",
    "\n",
    "Con el fin de enfocar el problema y mejorar la calidad del modelo, se realizó un filtro sobre el conjunto original de datos para conservar únicamente las observaciones relacionadas con tres de las causas de muerte más frecuentes:\n",
    "\n",
    "Infarto del miocardio\n",
    "\n",
    "Neumonía no especificada\n",
    "\n",
    "Fallecida, sin mención de complicación\n",
    "\n",
    "Esto convierte el problema en una tarea de clasificación multiclase, ya que el modelo debe asignar una observación a una de estas tres categorías posibles de causa de muerte.\n",
    "\n",
    "La predicción de la causa probable de muerte, basada en variables como edad, sexo, y año de registro, tiene una fuerte relevancia para el análisis poblacional y la planificación de políticas de salud pública, ya que permite identificar perfiles demográficos de riesgo frente a enfermedades críticas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ffd50a",
   "metadata": {},
   "source": [
    "2. Discutan si vale la pena agregar otros algoritmos que no habían tomado en cuenta o si consideran\n",
    "necesario quitar algunos otros que no traen buenos resultados o que, por alguna razón que pueda\n",
    "justificar y probar, no le hagan sentido. Para esta discusión, se recomienda fuertemente que pueda\n",
    "discutir a través de la experimentación práctica entrenando algunos modelos previos y evaluando\n",
    "sus resultados y demás consideraciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8023839",
   "metadata": {},
   "source": [
    "\n",
    "A lo largo del proyecto se ha realizado una exploración y evaluación progresiva de distintos algoritmos de aprendizaje supervisado, con el fin de identificar cuáles se adaptan mejor a la naturaleza del problema y los datos disponibles.\n",
    "\n",
    "Inicialmente, se investigaron e implementaron los siguientes algoritmos de clasificación:\n",
    "\n",
    "* **Random Forest**\n",
    "* **Naive Bayes**\n",
    "* **Support Vector Machines (SVM)**\n",
    "* **Regresión Logística**\n",
    "* **Gradient Boosting**\n",
    "\n",
    "Estos modelos fueron evaluados considerando métricas de clasificación como precisión, recall y F1-score, con énfasis en su capacidad para distinguir correctamente entre las tres clases definidas en la variable respuesta (`causa`).\n",
    "\n",
    "En esta nueva fase del proyecto, se están profundizando las pruebas con un subconjunto representativo de estos algoritmos, priorizando aquellos que mostraron mayor robustez y eficiencia en etapas anteriores. Específicamente, se están utilizando:\n",
    "\n",
    "* **Redes Neuronales Artificiales (RNA)**\n",
    "* **Regresión Logística**\n",
    "* **Naive Bayes**\n",
    "* **K-Nearest Neighbors (KNN)**\n",
    "* **Random Forest**\n",
    "\n",
    "La decisión de continuar con estos modelos se basa en sus buenos resultados preliminares, así como en su capacidad para adaptarse a distintos tipos de datos y configuraciones. Cada uno representa un enfoque distinto (lineal, probabilístico, basado en vecinos, árboles y redes), lo cual permite una comparación robusta y complementaria de rendimiento.\n",
    "\n",
    "Esta fase se enfoca no solo en comparar la precisión de cada modelo, sino también en identificar cómo afectan variables como el tamaño del conjunto de entrenamiento, el balance de clases, y el preprocesamiento de variables categóricas y numéricas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca533e0e",
   "metadata": {},
   "source": [
    "# 3. Seleccione (de esta primera experimentación) un mínimo de dos algoritmos a utilizar para responder la variable respuesta de su proyecto. No habrá un máximo de algoritmos por comparar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46eceb87",
   "metadata": {},
   "source": [
    "Se eligieron Random Forest y Regresión Logística como los dos mejores modelos basándose en los resultados obtenidos durante la evaluación de los modelos en las particiones 70/30, 80/20 y 85/15. Random Forest se destacó por su capacidad para manejar interacciones complejas entre las características y su robustez ante el sobreajuste, lo que lo hizo ideal para las características del conjunto de datos. A pesar de su mayor complejidad, mostró un rendimiento consistente y alto en comparación con otros modelos. Por otro lado, Regresión Logística fue seleccionada debido a su simplicidad y eficacia en tareas de clasificación multiclase, además de ofrecer una buena interpretación de las probabilidades de las enfermedades. Ambos modelos presentaron un buen equilibrio entre precisión, recall y f1-score, lo que los hace adecuados para la comparación y análisis de las tres enfermedades más frecuentes en el conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb6cbb3",
   "metadata": {},
   "source": [
    "Ademas, se eligió Red Neuronal Artificial (RNA). Se utilizó una red neuronal multicapa (MLPClassifier) que permite modelar relaciones no lineales entre las variables. El preprocesamiento incluyó la codificación de variables categóricas (get_dummies), normalización de características con StandardScaler y evaluación con diferentes proporciones de partición (70/30, 80/20 y 85/15). Se observaron resultados consistentes en accuracy y f1-score entre clases.\n",
    "\n",
    "Ambos modelos fueron evaluados con métricas como accuracy y f1-score para cada clase, lo cual permitió comparar su rendimiento en condiciones similares. Esta comparación ayudará a determinar cuál algoritmo generaliza mejor para el conjunto de datos en estudio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6eb0786",
   "metadata": {},
   "source": [
    "# 4. Explique el método que siguió para obtener los conjuntos de entrenamiento y prueba, el porcentaje de datos que hay en cada uno y si se encuentran balanceados o no, en caso de que la variable respuesta sea categórica. Sí es cuantitativa analice los atípicos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1163d670",
   "metadata": {},
   "source": [
    "Método de obtención de conjuntos de entrenamiento y prueba:\n",
    "Para obtener los conjuntos de entrenamiento y prueba, se utilizó la función train_test_split de la biblioteca scikit-learn, que realiza una división aleatoria de los datos. Los datos fueron divididos en tres proporciones estándar: 70/30, 80/20 y 85/15, en donde el primer valor indica el porcentaje de datos utilizados para entrenamiento y el segundo para la prueba. Este enfoque garantiza que los modelos sean entrenados con una parte significativa de los datos, mientras que se valida su rendimiento con un conjunto independiente de datos de prueba.\n",
    "\n",
    "Balanceo de clases con SMOTE:\n",
    "En cuanto al balanceo de clases, se utilizó la técnica SMOTE (Synthetic Minority Over-sampling Technique) para abordar el desequilibrio en la distribución de las clases de la variable respuesta. SMOTE genera ejemplos sintéticos para las clases minoritarias, lo que ayuda a equilibrar la representación de cada clase en el conjunto de entrenamiento. Este paso es crucial cuando se detecta que la variable respuesta (enfermedades) tiene una distribución desproporcionada, ya que asegura que el modelo pueda aprender de una representación más equitativa de todas las clases.\n",
    "\n",
    "Conversión de variables categóricas y tratamiento de valores atípicos:\n",
    "Como la variable respuesta es categórica (enfermedades), se aplicó LabelEncoder para convertir las clases en números, permitiendo que los modelos de clasificación trabajen con datos numéricos. Además, se realizó un análisis de los valores atípicos en la variable \"edad\". En los casos donde se encontraron valores erróneos (por ejemplo, el valor 999), se reemplazaron por la mediana de la variable \"edad\" para evitar que estos valores afectaran negativamente el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da363543",
   "metadata": {},
   "source": [
    "# 5. Utilice los algoritmos que determinó que serían los más útiles para aplicar a sus datos. Explique las transformaciones y/o el preprocesamiento que tuvo que hacer para aplicarlos correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19f0ab9",
   "metadata": {},
   "source": [
    "**REGRESION LOGISTICA**\n",
    "Para este análisis se eligió el algoritmo de regresión logística, ya que es adecuado para problemas de clasificación multiclase como el de predecir la causa de defunción fetal. Para poder aplicar correctamente este modelo, se realizaron los siguientes pasos de preprocesamiento y transformación de datos:\n",
    "\n",
    "1. **Filtrado de clases**: Se seleccionaron únicamente las tres causas de defunción más frecuentes, para simplificar el problema a una clasificación multiclase entre tres categorías.\n",
    "\n",
    "2. **Separación de variables**: Se separó la variable dependiente (causa) de las variables predictoras, descartando columnas no necesarias para el modelo.\n",
    "\n",
    "3. **Identificación de variables categóricas**: Se identificaron las columnas con tipo de dato categórico (tipo texto), ya que requieren transformación antes de ser utilizadas en modelos numéricos.\n",
    "\n",
    "4. **Codificación One-Hot**: Se utilizó OneHotEncoder para convertir las variables categóricas en variables numéricas binarias, evitando problemas de ordenamiento implícito.\n",
    "\n",
    "5. **Pipeline de procesamiento**: Se creó un pipeline utilizando ColumnTransformer y Pipeline de scikit-learn para integrar el preprocesamiento y el modelo de regresión logística en un solo flujo, asegurando la transformación coherente tanto para los datos de entrenamiento como de prueba.\n",
    "\n",
    "6. **Evaluación del modelo**: Se dividieron los datos en conjuntos de entrenamiento y prueba (70%-30%) y se evaluó el rendimiento del modelo con métricas como precisión, recall y F1-score usando classification_report. También se construyó una matriz de confusión para visualizar los aciertos y errores del modelo por clase.\n",
    "\n",
    "Este enfoque permitió aplicar correctamente la regresión logística a un problema multiclase, con un tratamiento apropiado de los datos categóricos y una evaluación detallada de los resultados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547a1de1",
   "metadata": {},
   "source": [
    "![Datos RNA](foto1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b604d9f6",
   "metadata": {},
   "source": [
    "Modelo RNA:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97d470",
   "metadata": {},
   "source": [
    "\n",
    "Uno de los algoritmos más útiles para nuestro problema de clasificación fue la Red Neuronal Artificial, específicamente un perceptrón multicapa (MLPClassifier de scikit-learn), ya que permite modelar relaciones no lineales y complejas entre las variables.\n",
    "\n",
    "Para aplicar correctamente este modelo, fue necesario realizar el siguiente preprocesamiento y transformaciones sobre los datos:\n",
    "\n",
    "1. Filtrado de clases: Se trabajó únicamente con tres causas de defunción específicas (E149, I219, J189), para facilitar la clasificación multiclase y asegurar suficiente representatividad en cada categoría.\n",
    "\n",
    "2. Codificación de variables:  \n",
    "   - Se utilizó get_dummies para transformar todas las variables categóricas en variables numéricas binarias.  \n",
    "   - La variable objetivo (causa) fue transformada a números enteros mediante LabelEncoder, para que la red neuronal pudiera interpretarla.\n",
    "\n",
    "3. Normalización de datos:  \n",
    "   - Se aplicó StandardScaler para escalar todas las variables numéricas a una distribución con media cero y desviación estándar uno, lo cual es crucial para mejorar la convergencia del entrenamiento.\n",
    "\n",
    "4. División de datos:  \n",
    "   - Se dividieron los datos en conjuntos de entrenamiento y prueba con distintas proporciones (70/30, 80/20 y 85/15), lo que permitió comparar el rendimiento del modelo bajo diferentes escenarios de generalización.\n",
    "\n",
    "5. Entrenamiento del modelo:  \n",
    "   - Se entrenó el MLPClassifier con una arquitectura simple (una capa oculta de 30 neuronas), iterando hasta 200 épocas, y se evaluó con métricas como accuracy, f1-score y matriz de confusión.\n",
    "\n",
    "Este preprocesamiento permitió adaptar correctamente el conjunto de datos a los requerimientos del algoritmo y evitar errores comunes como el uso de variables categóricas sin codificar o el desbalance en las clases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40433dd",
   "metadata": {},
   "source": [
    "Modelo Random Forest: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3af9e4",
   "metadata": {},
   "source": [
    "Otro de los algoritmos seleccionados para resolver el problema de clasificación fue el modelo de Random Forest, debido a su capacidad para manejar conjuntos de datos con muchas variables, su resistencia al sobreajuste y su buen desempeño sin necesidad de demasiada parametrización.\n",
    "\n",
    "Para aplicar correctamente este algoritmo a los datos de defunciones fetales, se realizaron las siguientes transformaciones y preprocesamiento:\n",
    "\n",
    "1. Se seleccionaron únicamente las tres causas de muerte más frecuentes (E149, I219, J189), con el fin de enfocarnos en una clasificación multiclase equilibrada y manejable.\n",
    "\n",
    "2. Se utilizó la función get_dummies de pandas para convertir todas las variables categóricas en variables numéricas binarias, permitiendo que el algoritmo pudiera interpretarlas sin necesidad de orden implícito.\n",
    "\n",
    "3. Se rellenaron los valores faltantes con ceros utilizando fillna(0) para asegurar que no existieran NaN durante el entrenamiento del modelo.\n",
    "\n",
    "4. Se aplicaron diferentes proporciones de partición entre entrenamiento y prueba (como 70/30 y 80/20) con train_test_split, lo que permitió evaluar la estabilidad del modelo y su capacidad de generalización.\n",
    "\n",
    "5. Se utilizó RandomForestClassifier del paquete scikit-learn con parámetros por defecto. Este clasificador construye múltiples árboles de decisión y promedia sus resultados, lo cual mejora la precisión y reduce el riesgo de sobreajuste.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3da471",
   "metadata": {},
   "source": [
    "# 6. Cree varios modelos, (al menos 3 con cada algoritmo) con los algoritmos seleccionados. Varíe los parámetros buscando el mejor modelo sin caer en un modelo desajustado o sobreajustado. Construya un modelo final con los mejores parámetros. Explique con datos como llegó a ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d529a79",
   "metadata": {},
   "source": [
    "Modelos con regresión logística "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53eec1c",
   "metadata": {},
   "source": [
    "Modelo_1 (C=0.1): F1 promedio = 0.4548 ± 0.0038\n",
    "\n",
    "Modelo_2 (C=1): F1 promedio = 0.4566 ± 0.0046\n",
    "\n",
    "Modelo_3 (C=10): F1 promedio = 0.4576 ± 0.0052"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef641ff8",
   "metadata": {},
   "source": [
    "El mejor modelo en este caso es el modelo 3, ya que tiene el mayor F1 score promedio con un valor de 0.4576, lo cual significa que clasifica mejor en promedio que los otros modelos, indica que logra un buen balance entre precisión y sensibilidad para las 3 enfermedades (Diabetes, infarto y neumonia).\n",
    "\n",
    "Presenta una desviación estándar razonable de 0.0052, aunque es un poco más alta que en los otros modelos, sigue siendo estable, lo cual sugiere que el modelo no sufre de sobreajuste. Por otro lado, un valor de c=10 le permite al modelo tener más flexibilidad para aprender patrones, sin memorizar el ruido."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b24eac",
   "metadata": {},
   "source": [
    "Modelo de RNA: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaf2137",
   "metadata": {},
   "source": [
    "Para el caso del algoritmo de RNA, se construyeron tres modelos distintos variando la proporción de entrenamiento/prueba: 70/30, 80/20 y 85/15. En cada configuración, se mantuvieron los mismos hiperparámetros para observar el efecto del tamaño de entrenamiento en el rendimiento general del modelo.\n",
    "\n",
    "Además, se experimentó con distintos parámetros del modelo MLPClassifier para evitar tanto el subajuste (modelo demasiado simple) como el sobreajuste (modelo demasiado complejo). Los parámetros evaluados incluyeron:\n",
    "\n",
    "- hidden_layer_sizes: número de neuronas en la capa oculta (por ejemplo, (30,), (50,))\n",
    "- max_iter: número máximo de iteraciones (se usó 200 como valor base)\n",
    "- random_state: para reproducibilidad\n",
    "\n",
    "A continuación, se muestra un resumen de resultados con las proporciones de entrenamiento evaluadas:\n",
    "\n",
    "| Proporción | Accuracy | F1-score Diabetes | F1-score Infarto | F1-score Neumonía |\n",
    "|------------|----------|-------------------|------------------|-------------------|\n",
    "| 70/30      | 0.60     | 0.43              | 0.65             | 0.64              |\n",
    "| 80/20      | 0.60     | 0.43              | 0.64             | 0.65              |\n",
    "| 85/15      | 0.60     | 0.47              | 0.63             | 0.65              |\n",
    "\n",
    "Se observa que el modelo con proporción 85/15 mostró un mejor equilibrio entre las clases, particularmente para la clase menos representada (Diabetes), por lo que fue elegido como el modelo final.\n",
    "\n",
    "Este modelo final mantiene una arquitectura simple (una sola capa oculta con 30 neuronas) y generaliza bien, sin mostrar síntomas evidentes de sobreajuste.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08df4fb",
   "metadata": {},
   "source": [
    "# 7. Discuta los resultados de los algoritmos incluyendo la matriz de confusión obtenida, en caso de que sea un problema de clasificación, o la métrica de error que considere mejor si el problema es de regresión. Recuerde incluir textos y gráficas (de ser necesarias) para apoyar su explicación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df4ec76",
   "metadata": {},
   "source": [
    "Modelo RNA:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e48ea2",
   "metadata": {},
   "source": [
    "![Matriz de Confusión](matrizdeconfusionRNA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e25e6e",
   "metadata": {},
   "source": [
    "A partir de la matriz se puede observar lo siguiente:\n",
    "\n",
    "- La clase I219 (Infarto) fue la mejor clasificada, con un 73% de los casos correctamente predichos.\n",
    "- La clase J189 (Neumonía) tuvo una precisión moderada, con un 62% de aciertos.\n",
    "- La clase E149 (Diabetes) fue la que presentó mayor confusión, con solo un 34% de predicciones correctas, y una gran parte de los casos siendo mal clasificados como I219.\n",
    "\n",
    "Estos resultados sugieren que el modelo tiene dificultades para distinguir correctamente entre causas similares o poco representadas. A pesar de esto, la RNA fue capaz de capturar patrones útiles, especialmente en clases con mayor frecuencia.\n",
    "\n",
    "Además del accuracy, se analizaron los f1-scores por clase, los cuales reflejaron el mismo patrón: mayor desempeño para I219, desempeño medio para J189 y menor para E149. Esto es importante porque indica un desbalance en la capacidad del modelo de generalizar en clases menos frecuentes.\n",
    "\n",
    "Para mejorar estos resultados, se podría considerar aplicar técnicas como balanceo de clases, aumento de datos (data augmentation) o ajustar hiperparámetros de la red neuronal (tamaño de capa oculta, función de activación, etc.).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c01e30",
   "metadata": {},
   "source": [
    "Modelo Regresion Logistica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c642f0",
   "metadata": {},
   "source": [
    "![Matriz de Confusión](matrizdeconfusionRegLog.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc64488",
   "metadata": {},
   "source": [
    "A partir de esta matriz, se puede observar:\n",
    "\n",
    "- La clase I219 (Infarto) fue también la mejor clasificada, con alrededor del 75% de aciertos.\n",
    "- La clase J189 (Neumonía) tuvo un desempeño medio, con valores cercanos al 60% de predicción correcta.\n",
    "- La clase E149 (Diabetes) mostró el menor nivel de precisión, con alrededor del 35% de aciertos y alta confusión con la clase I219.\n",
    "\n",
    "En comparación con el modelo de red neuronal, la regresión logística obtuvo un desempeño ligeramente inferior en f1-score para las clases mayoritarias, pero con una mayor simplicidad en la implementación y mejor interpretabilidad de los coeficientes del modelo.\n",
    "\n",
    "Ambos modelos coincidieron en que la clase E149 es la más difícil de predecir, lo cual puede estar relacionado con la similitud en los patrones de variables o una menor representación de esta clase en los datos.\n",
    "\n",
    "Se concluye que la regresión logística es una buena opción base para clasificación multiclase, pero podría complementarse con modelos más complejos como redes neuronales si se busca mejorar la sensibilidad en clases minoritarias.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
